# Default VQ-VAE Training Configuration
# This is a template - copy and customize for specific experiments
#
# IMPORTANT: This config uses the NEW multi-family nested format.
# See docs/vqvae/multi-family-encoders.md for migration guide from old format.

# Dataset
dataset_path: null  # Path to HDF5 dataset (required)
max_samples: null   # Limit dataset size for testing (null = use all)

# Feature Families
# Define one or more feature families to train on
# Each family needs an encoder type and encoder-specific parameters
families:
  # Example: SUMMARY family (uncomment to use)
  # summary:
  #   encoder: MLPEncoder
  #   encoder_params:
  #     hidden_dims: [256, 128]
  #     output_dim: 64
  #     dropout: 0.1
  #     activation: "relu"
  #     batch_norm: true

  # Example: ARCHITECTURE family (uncomment to use)
  # architecture:
  #   encoder: MLPEncoder
  #   encoder_params:
  #     hidden_dims: [128, 64]
  #     output_dim: 64
  #     dropout: 0.1
  #     activation: "relu"
  #     batch_norm: true

  # Example: INITIAL family (uncomment to use)
  # initial:
  #   encoder: MLPEncoder
  #   encoder_params:
  #     hidden_dims: [128, 64]
  #     output_dim: 64
  #     dropout: 0.1
  #     activation: "relu"
  #     batch_norm: true

  # Example: TEMPORAL family (when implemented)
  # temporal:
  #   encoder: TDCNNEncoder  # Future: specialized encoder for temporal features
  #   encoder_params:
  #     ... (TBD)

# VQ-VAE Architecture
model:
  # Feature encoder parameters
  group_embedding_dim: 64   # Fixed embedding size per category
  group_hidden_dim: 128     # Hidden dimension for category MLPs (typically 2Ã— group_embedding_dim)

  # Hierarchical levels (empty list = intelligent auto-scaling)
  levels: []
  # Or explicit override:
  # levels:
  #   - {latent_dim: 32, num_tokens: 128}  # L0: Coarse (auto-computed if null)
  #   - {latent_dim: 16, num_tokens: 256}  # L1: Medium (auto-computed if null)
  #   - {latent_dim: 8, num_tokens: 512}   # L2: Fine (auto-computed if null)

  # VQ-VAE hyperparameters
  commitment_cost: 0.25     # VQ commitment loss weight
  use_ema: true             # Use EMA for codebook updates
  decay: 0.99               # EMA decay rate
  dropout: 0.1              # Dropout rate in encoders

  # Auxiliary loss weights (applied at model level)
  orthogonality_weight: 0.1      # Codebook diversity loss weight
  informativeness_weight: 0.1    # Partial decoder loss weight

# Training
training:
  # Optimization
  batch_size: 512
  learning_rate: 0.0005
  num_epochs: 500
  optimizer: "adam"
  scheduler: null           # Learning rate scheduler (null = none)
  warmup_epochs: 0          # Learning rate warmup epochs

  # Category discovery (for auto mode)
  category_assignment: "auto"           # "auto" (clustering) or "manual"
  num_categories_auto: null             # null = auto-determine via silhouette, or specify K
  min_features_per_category: 3          # Minimum features per category
  max_clusters: 25                      # Maximum number of clusters to consider
  orthogonality_target: 0.15            # Target inter-category orthogonality (0-1, lower = more orthogonal)
  # For manual mode: specify category_mapping_file instead
  # category_assignment: "manual"
  # category_mapping_file: "configs/vqvae/my_category_mapping.json"

  # Loss weights (applied during training)
  reconstruction_weight: 1.0
  vq_weight: 1.0
  orthogonality_weight: 0.1
  informativeness_weight: 0.1
  topo_weight: 0.3                      # Topographic similarity loss weight
  topo_samples: 512                     # Number of samples for topographic loss computation

  # Checkpointing
  checkpoint_dir: null                  # Directory for checkpoints (required)
  save_every: null                      # Save checkpoint every N epochs (null = only save best)

  # Callbacks
  early_stopping_patience: 100          # Stop if no improvement for N epochs
  early_stopping_min_delta: 0.001       # Minimum improvement threshold
  dead_code_reset_interval: 100         # Reset dead codes every N epochs (0 = disable)
  dead_code_threshold: 10.0             # Percentile threshold for dead code detection (0-100)
  dead_code_max_reset_fraction: 0.25    # Max fraction of codebook to reset at once

  # Validation
  val_every_n_epochs: 5                 # Validate every N epochs (reduces overhead)

  # Performance
  use_torch_compile: true               # Use torch.compile() for JIT compilation (~30-40% speedup)

# Logging
logging:
  wandb: false              # Enable Weights & Biases logging
  log_interval: 100         # Log training metrics every N batches
  eval_interval: 500        # Evaluate on validation set every N batches
  verbose: true             # Print detailed progress

# Random seed
random_seed: 42
