version: "1.0"

metadata:
  name: "lambda_labs_100"
  description: |
    100-operator test for Lambda Labs A100 with optimized batch size.
    Based on baseline_10k config with A100-specific optimizations.
    Full 500 timesteps for production-quality features.
  author: "Spinlock Team"
  created: "2026-01-02"
  purpose: |
    Validate Lambda Labs infrastructure at scale before 100K run:
    - Test A100 memory capacity with batch_size=5
    - Verify 500-timestep feature extraction performance
    - Validate SSH job submission and monitoring
    - Confirm file download from Lambda Labs instance

    Runtime: ~10-15 minutes for 100 operators
    Cost: ~$0.20-0.30

# Same 14-dimensional parameter space as baseline_10k
parameter_space:
  architecture:
    num_layers:
      type: integer
      bounds: [2, 5]

    base_channels:
      type: integer
      bounds: [16, 64]

    kernel_size:
      type: choice
      choices: [3, 5, 7]

    activation:
      type: choice
      choices: ["gelu"]

    dropout_rate:
      type: continuous
      bounds: [0.0, 0.3]

  stochastic:
    noise_type:
      type: choice
      choices: ["gaussian"]

    noise_scale:
      type: continuous
      bounds: [0.00001, 1.0]
      log_scale: true

    noise_schedule:
      type: choice
      choices: ["constant"]

    spatial_correlation:
      type: continuous
      bounds: [0.0, 0.3]

  operator:
    normalization:
      type: choice
      choices: ["instance"]

    grid_size:
      type: choice
      choices: [128]

  evolution:
    update_policy:
      type: choice
      choices: ["residual", "convex"]
      weights: [0.75, 0.25]

# Sampling configuration
sampling:
  strategy: "sobol_stratified"

  sobol:
    scramble: true
    seed: 42

  stratification:
    method: "adaptive"
    num_strata_per_dim: 3
    min_samples_per_stratum: 3

  validation:
    check_discrepancy: true
    check_correlation: true

  total_samples: 96  # 96 operators for validation (divisible by batch_size)
  batch_size: 8  # Optimized for A100 40GB (aggressive but safe)

# Simulation with full IC basis (same as baseline_10k)
simulation:
  device: "cuda"

  parallelism:
    strategy: "data_parallel"
    devices: "auto"

  input_generation:
    method: "sampled"

    # Equal weighting: 25% per IC family (same as baseline_10k)
    ic_type_weights:
      # Gaussian noise family (25% total, split across 5 variance levels)
      gaussian_random_field_v0: 0.05   # variance=0.25
      gaussian_random_field_v1: 0.05   # variance=0.5
      gaussian_random_field_v2: 0.05   # variance=1.0
      gaussian_random_field_v3: 0.05   # variance=2.0
      gaussian_random_field_v4: 0.05   # variance=4.0

      # Band-limited noise family (25% total)
      multiscale_grf_low: 0.0833
      multiscale_grf_mid: 0.0833
      multiscale_grf_high: 0.0834

      # Sinusoid family (25%)
      structured: 0.25

      # Localized blob family (25%)
      localized: 0.25

    # IC-specific configurations (same as baseline_10k)
    gaussian_random_field_v0:
      length_scale: 0.05
      variance: 0.25

    gaussian_random_field_v1:
      length_scale: 0.05
      variance: 0.5

    gaussian_random_field_v2:
      length_scale: 0.05
      variance: 1.0

    gaussian_random_field_v3:
      length_scale: 0.05
      variance: 2.0

    gaussian_random_field_v4:
      length_scale: 0.05
      variance: 4.0

    multiscale_grf_low:
      scales: [0.30, 0.35, 0.40]
      variance: 1.0

    multiscale_grf_mid:
      scales: [0.08, 0.10, 0.12]
      variance: 1.0

    multiscale_grf_high:
      scales: [0.02, 0.03, 0.04]
      variance: 1.0

    structured:
      num_structures: 3
      structure_types: ["stripe"]

    localized:
      num_blobs: 5
      min_width: 5.0
      max_width: 15.0

  precision: "float16"  # Same as baseline

  num_realizations: 5  # Full 5 realizations
  num_timesteps: 500  # Full 500 timesteps for production-quality temporal features

  # Operator feature extraction disabled (same as baseline - redundant with temporal features)
  extract_operator_features: false

# Dataset output configuration
dataset:
  output_path: "lambda_labs_100.h5"

  storage:
    backend: "hdf5"
    compression: "gzip"
    compression_level: 4
    chunk_size: 8  # Matches batch_size for optimal I/O

    # Feature-only mode (same as baseline)
    store_trajectories: false

# Cloud configuration - Lambda Labs with built-in file storage
cloud:
  provider:
    enabled: true
    provider: "lambda_labs"

  lambda_labs:
    api_key: "${LAMBDA_API_KEY}"  # Loaded from environment
    gpu_type: "A100"
    instance_type: "gpu_1x_a100_sxm4"
    region: "us-east-1"  # Updated to region with available capacity
    ssh_key_name: "Daniel Home Desktop"  # Must match key name in Lambda Labs dashboard

    # Safety limits
    max_cost_per_hour: 1.50
    auto_shutdown_on_completion: true

    # Remote execution
    remote_working_dir: "/home/ubuntu/spinlock"

  # Use Lambda Labs built-in file storage (NOT S3)
  lambda_labs_storage:
    remote_path: "/home/ubuntu/datasets"  # Where dataset is saved on Lambda instance
    local_download_path: "datasets/"      # Download to local datasets/ directory after generation

# Logging
logging:
  level: "INFO"

# =============================================================================
# Expected Results
# =============================================================================
#
# Scale:
# - 100 operators × 5 realizations = 500 total samples
# - 128×128 spatial resolution
# - 500 timesteps per trajectory
# - Feature-only mode: ~50MB storage
#
# Runtime (A100, batch_size=5):
# - Generation: ~8-12 minutes (10-20× faster than local)
# - Feature extraction: Inline (included in generation time)
# - Download: <10 seconds (50MB file)
# - Total: ~10-15 minutes end-to-end
#
# Cost:
# - Lambda Labs A100: $1.10/hr
# - 10-15 minutes = ~$0.18-0.28
# - Negligible cost for validation
#
# Performance vs local (batch_size=2, 100 timesteps):
# - A100 batch_size=5: 2.5× larger batches
# - 500 vs 100 timesteps: 5× more compute per operator
# - Expected: ~2× faster per operator despite 5× more work (A100 efficiency)
#
# Usage:
#   # Lambda Labs test
#   poetry run spinlock cloud-generate \
#     --config configs/cloud/lambda_labs_100.yaml \
#     --provider lambda_labs \
#     --monitor
#
# =============================================================================
